apiVersion: argoproj.io/v1alpha1
kind: WorkflowTemplate
metadata:
  name: "model-inference-template"
spec:
  entrypoint: main
  arguments:
    parameters:
    - name: run_name
    - name: pvc
      value: 'stable-diffusion-model-cache'
    - name: model
      value: 'stabilityai/stable-diffusion-2-1-base'
    - name: inference_image
      value: 'navarrepratt/sd-inference'  # TODO: Update with CoreWeave hosted image
    - name: inference_tag
      value: 'df-14-3'
    - name: region
      value: 'LAS1'
    - name: inference_gpu
      value: 'Quadro_RTX_5000'

  templates:
  - name: main
    steps:
    - - name: inference
        template: model-inference-service
        arguments:
          parameters:
            - name: command
              value: '["python3", "/app/service.py", "--model-id", "/mnt/pvc/models/{{workflow.parameters.model}}"]'
  - name: model-inference-service
    inputs:
      parameters:
        - name: command
    resource:
      action: apply
      manifest: |
        apiVersion: serving.kubeflow.org/v1beta1
        kind: InferenceService
        metadata:
          name: inference-{{ workflow.parameters.run_name }}
          annotations:
            autoscaling.knative.dev/scaleToZeroPodRetentionPeriod: 20m
        spec:
          predictor:
            minReplicas: 0
            maxReplicas: 1
            affinity:
              nodeAffinity:
                requiredDuringSchedulingIgnoredDuringExecution:
                  nodeSelectorTerms:
                    - matchExpressions:
                        - key: gpu.nvidia.com/class
                          operator: In
                          values:
                            - "{{workflow.parameters.inference_gpu}}"
                        - key: topology.kubernetes.io/region
                          operator: In
                          values:
                            - "{{workflow.parameters.region}}"
            containers:
              - name: kfserving-container
                image: "{{workflow.parameters.inference_image}}:{{workflow.parameters.inference_tag}}"
                imagePullPolicy: IfNotPresent
                command: {{inputs.parameters.command}}
                env:
                  - name: STORAGE_URI
                    value: pvc://{{ workflow.parameters.pvc }}/
                resources:
                  requests:
                    nvidia.com/gpu: 1
                    cpu: 4
                    memory: 8Gi
                  limits:
                    nvidia.com/gpu: 1
                    cpu: 12
                    memory: 60Gi
